# Speech Language Models DDMP

## Overview
This project is part of the "Data-driven Machine Perception" (DDMP) course and focuses on building spoken dialogue systems directly from raw audio recordings. Our approach, inspired by the Zero Resource Speech Challenge, aims to support low-resource languages and explore expressive communication methods without relying on text.

## Motivations
- **Inclusivity**: Targeting low-resource languages to make AI dialogue systems more accessible.
- **Expressiveness**: Leveraging the richness of audio for more nuanced interactions.
- **Language Acquisition Insights**: Offering insights into human language understanding.

## Research and Implementation
We're building upon Googleâ€™s open-source AudioLM, focusing on:
- Evaluating speech tokenizers.
- Improving acoustic quality measurements.
- Extending to music generation.

## Scaling Laws for SLMs
Derived scaling laws guide the efficient scaling of speech language models, balancing computational resources with performance.

## Contributing
Contributions are welcome! Opportunities include:
- **Model Evaluation**: Testing speech tokenizers and refining evaluation metrics.
- **Acoustic Quality Analysis**: Enhancing speech realism and intelligibility measurement.
- **Creative Applications**: Exploring new applications, such as music generation.

## References and Further Reading
- Generative Spoken Language Modeling from Raw Audio
- AudioLM: A Language Modeling Approach to Audio Generation
- Scaling Laws for Neural Language Models